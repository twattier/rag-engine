# Story 3.4: Implement Hybrid Retrieval Pipeline (Vector + Graph + BM25)

**Epic:** Epic 3 - Graph-Based Retrieval, Knowledge Graph Construction & Visualization
**Story ID:** 3.4
**Status:** Draft
**Estimated Effort:** 8 story points (2-3 days)

---

## User Story

**As a** RAG Engine user,
**I want** queries to leverage vector similarity, graph traversal, and keyword matching,
**so that** retrieval results are more accurate than single-method approaches.

---

## Acceptance Criteria

1. API endpoint `POST /api/v1/query` accepts: query_text, retrieval_mode ("naive", "local", "global", "hybrid"), top_k (default: 10)
2. Retrieval modes implemented using LightRAG's query modes:
   - **Naive**: Simple vector similarity search
   - **Local**: Entity-centric retrieval with 1-hop graph traversal
   - **Global**: Community detection and high-level concept retrieval
   - **Hybrid**: Combines local + global retrieval strategies
3. BM25 sparse retrieval integrated for keyword matching (complements dense embeddings)
4. Retrieval pipeline returns: list of relevant text chunks, source_document_ids, relevance_scores, retrieved_entities
5. Query response includes retrieval_mode_used and retrieval_latency_ms for transparency
6. Embedding generation uses configured embedding model (sentence-transformers or OpenAI via LiteLLM)
7. Performance target: P95 latency < 2 seconds for 1000-document knowledge base
8. Integration test compares retrieval modes on same query, validates hybrid returns more results than naive

---

## Tasks / Subtasks

- [ ] **Task 1: Create query API endpoint** (AC: 1)
  - [ ] Create `services/api/app/routers/query.py`
  - [ ] Implement `POST /api/v1/query` endpoint
  - [ ] Define `QueryRequest(query_text, retrieval_mode, top_k, metadata_filters)` Pydantic model
  - [ ] Define `QueryResponse(response, context_chunks, entities, latency_ms)` model
  - [ ] Add input validation: retrieval_mode enum, top_k range (1-100)

- [ ] **Task 2: Implement retrieval modes** (AC: 2, 3)
  - [ ] Create `services/lightrag-integration/app/services/query_service.py`
  - [ ] Implement `query_naive(query_text, top_k)` - vector similarity only
  - [ ] Implement `query_local(query_text, top_k)` - entity-centric + 1-hop traversal
  - [ ] Implement `query_global(query_text, top_k)` - community detection
  - [ ] Implement `query_hybrid(query_text, top_k)` - combine local + global
  - [ ] Integrate BM25 keyword matching using `rank-bm25` library
  - [ ] Combine vector + BM25 scores using weighted fusion (0.7 vector + 0.3 BM25)

- [ ] **Task 3: Build retrieval response** (AC: 4, 5)
  - [ ] Parse LightRAG query response
  - [ ] Extract: text_chunks, source_document_ids, relevance_scores, retrieved_entities
  - [ ] Calculate retrieval_latency_ms (start → end timing)
  - [ ] Return structured QueryResponse with all fields

- [ ] **Task 4: Configure embedding model** (AC: 6)
  - [ ] Load embedding model from env: `EMBEDDING_MODEL` (default: all-MiniLM-L6-v2)
  - [ ] Support sentence-transformers models (local, no API costs)
  - [ ] Support OpenAI embeddings via LiteLLM (optional, requires API key)
  - [ ] Cache embedding model in memory (load once at startup)

- [ ] **Task 5: Optimize for performance** (AC: 7)
  - [ ] Add Neo4j query optimizations: use indexes, limit result sizes
  - [ ] Implement caching for frequent queries (optional, in-memory LRU cache)
  - [ ] Profile query latency with pytest-benchmark
  - [ ] Target: P95 < 2s for 1000 documents

- [ ] **Task 6: Create integration tests** (AC: 8)
  - [ ] Create `services/api/tests/integration/test_hybrid_retrieval.py`
  - [ ] Test: Query "Python programming skills" in naive mode
  - [ ] Test: Query same in hybrid mode, verify returns more/better results
  - [ ] Test: Measure latency, assert < 2s
  - [ ] Test: Validate response structure (chunks, entities, scores)

---

## Dev Notes

### Retrieval Modes Explained

**Naive Mode**: Vector similarity search only
- Embed query → find similar embeddings in Neo4j vector index
- Fast but limited to lexical/semantic similarity

**Local Mode**: Entity-centric retrieval
- Extract entities from query → find matching entities in graph
- Traverse 1-hop relationships to find connected entities
- Retrieve documents containing these entities

**Global Mode**: Community detection
- Identify high-level concepts/topics in query
- Use graph clustering to find relevant document clusters
- Retrieve representative documents from clusters

**Hybrid Mode**: Combines local + global
- Best of both worlds: entity-centric + high-level concepts
- Highest recall but slightly slower

### BM25 Integration

```python
from rank_bm25 import BM25Okapi

# Build BM25 index from document corpus
tokenized_corpus = [doc.text.split() for doc in documents]
bm25 = BM25Okapi(tokenized_corpus)

# Query
query_tokens = query_text.split()
bm25_scores = bm25.get_scores(query_tokens)

# Combine with vector scores
final_scores = 0.7 * vector_scores + 0.3 * bm25_scores
```

### Performance Targets (NFR1)

- P95 latency < 2 seconds for 1000-document knowledge base
- Measure with: `pytest-benchmark`, `time` module
- Optimize: Neo4j indexes, limit top_k, cache embeddings

---

## Testing

### Test Scenarios
- Naive vs Hybrid comparison (Hybrid should return more results)
- Latency measurement (<2s for 1000 docs)
- Empty query handling (graceful error)
- Invalid retrieval mode (validation error)

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-17 | 1.0 | Story created from Epic 3 | Sarah (PO Agent) |

---

## Dev Agent Record
<!-- Populated during implementation -->

## QA Results
<!-- Results from QA Agent review -->
