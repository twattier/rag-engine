# Story 2.3: Create Document Ingestion API Endpoint with Metadata Support

**Epic:** Epic 2 - Multi-Format Document Ingestion Pipeline
**Story ID:** 2.3
**Status:** Draft
**Estimated Effort:** 5 story points (6-8 hours)

---

## User Story

**As a** RAG Engine user,
**I want** to upload documents via REST API with custom metadata,
**so that** I can populate my knowledge base programmatically.

---

## Acceptance Criteria

1. API service exposes `POST /api/v1/documents/ingest` endpoint accepting:
   - Document file (multipart/form-data)
   - Metadata JSON object (validated against schema)
   - Optional: expected_entity_types (list of domain-specific entity types)
2. Endpoint orchestrates: RAG-Anything parsing → store raw parsed content → queue for LightRAG processing (Epic 3 dependency)
3. Response includes: document_id (UUID), ingestion_status ("parsing", "queued"), metadata confirmation
4. **Neo4j Storage Schema:** Parsed document content stored in Neo4j with the following schema:
   - Node label: `(:Document {id: UUID, filename: string, status: string, metadata: JSON, ingestion_date: datetime, size_bytes: int})`
   - Relationship: `(:Document)-[:HAS_CONTENT]->(:ParsedContent {text: string, format: string, tables: JSON, images: JSON})`
   - Index created on `Document.id` and `Document.metadata` fields for query optimization
5. API handles file size limits (configurable, default 50MB) and returns 413 for oversized files
6. **Authentication & Rate Limiting:** Rate limiting implemented using mock API key validation for Epic 2 testing (configurable, default 10 requests/minute per API key). Note: Real API key authentication will be implemented in Epic 4 Story 4.2
7. **LightRAG Queue Mechanism:** Documents queued for LightRAG processing using Python asyncio queue (in-memory for MVP). Note: May upgrade to Redis queue in Epic 5 for production scalability
8. OpenAPI documentation updated with ingestion endpoint specification and examples
9. Integration test successfully ingests sample PDF with metadata

---

## Tasks / Subtasks

- [ ] **Task 1: Create document ingestion router** (AC: 1)
  - [ ] Create `services/api/routers/documents.py` module
  - [ ] Define `POST /api/v1/documents/ingest` endpoint
  - [ ] Add multipart/form-data file upload handling
  - [ ] Add metadata JSON parsing from form data
  - [ ] Add optional expected_entity_types parameter
  - [ ] Implement request validation with Pydantic models

- [ ] **Task 2: Implement file validation and size limits** (AC: 5)
  - [ ] Create file size validation function
  - [ ] Add `MAX_FILE_SIZE_MB` to config (default 50MB)
  - [ ] Return 413 Payload Too Large for oversized files
  - [ ] Validate file extension against supported formats
  - [ ] Return 400 Bad Request for unsupported formats

- [ ] **Task 3: Integrate metadata validation** (AC: 1)
  - [ ] Import metadata schema dependency from Story 2.2
  - [ ] Add metadata validation to ingestion endpoint
  - [ ] Return 422 Unprocessable Entity for invalid metadata
  - [ ] Include detailed validation errors in response

- [ ] **Task 4: Implement RAG-Anything orchestration** (AC: 2)
  - [ ] Create `services/api/services/document_service.py`
  - [ ] Implement `async def ingest_document()` function
  - [ ] Call RAG-Anything service `/parse` endpoint
  - [ ] Handle RAG-Anything parsing errors
  - [ ] Store parsed content_list temporarily

- [ ] **Task 5: Implement Neo4j storage for parsed documents** (AC: 4)
  - [ ] Create Neo4j Document node creation function
  - [ ] Implement `(:Document)` node with required properties
  - [ ] Create `(:ParsedContent)` node for content_list
  - [ ] Create `[:HAS_CONTENT]` relationship
  - [ ] Add indexes on `Document.id` and `Document.metadata`
  - [ ] Use parameterized Cypher queries

- [ ] **Task 6: Implement LightRAG processing queue** (AC: 7)
  - [ ] Create `services/api/services/queue_service.py`
  - [ ] Implement asyncio queue for document processing
  - [ ] Create background task for LightRAG processing
  - [ ] Add queue status tracking
  - [ ] Handle queue processing errors gracefully

- [ ] **Task 7: Implement mock rate limiting** (AC: 6)
  - [ ] Create `services/api/middleware/rate_limiter.py`
  - [ ] Implement in-memory rate limiter with API key tracking
  - [ ] Add mock API key validation (accept any non-empty key)
  - [ ] Return 429 Too Many Requests when limit exceeded
  - [ ] Add rate limit configuration (default 10 req/min)
  - [ ] Add rate limit headers to responses

- [ ] **Task 8: Create response models** (AC: 3)
  - [ ] Create `services/api/models/responses.py`
  - [ ] Define `DocumentIngestResponse` Pydantic model
  - [ ] Include document_id, ingestion_status, metadata fields
  - [ ] Define error response models (400, 413, 422, 429)

- [ ] **Task 9: Update OpenAPI documentation** (AC: 8)
  - [ ] Add endpoint description with examples
  - [ ] Document multipart/form-data request format
  - [ ] Include request/response JSON examples
  - [ ] Document error responses with status codes
  - [ ] Add metadata schema reference

- [ ] **Task 10: Create integration tests** (AC: 9)
  - [ ] Create `services/api/tests/integration/test_document_ingestion.py`
  - [ ] Test successful PDF ingestion with metadata
  - [ ] Test file size limit (413 response)
  - [ ] Test unsupported file type (400 response)
  - [ ] Test invalid metadata (422 response)
  - [ ] Test rate limiting (429 response)
  - [ ] Test document retrieval from Neo4j after ingestion
  - [ ] Use pytest fixtures for test files

---

## Dev Notes

### Tech Stack
[Source: architecture/tech-stack.md]

- **Python**: 3.11+ (async/await support)
- **Backend Framework**: FastAPI 0.115+ (async endpoints, multipart handling)
- **Validation**: Pydantic 2.x (request/response models)
- **Graph Database**: Neo4j 5.x (document and content storage)
- **Neo4j Driver**: neo4j Python driver (Cypher queries)
- **Queue**: Python asyncio.Queue (in-memory queue for MVP)
- **Testing Framework**: pytest with pytest-asyncio
- **HTTP Testing**: httpx AsyncClient for integration tests

### Project Structure
[Source: architecture/unified-project-structure.md]

File locations for implementation:

```
services/api/
├── main.py                      # FastAPI app (register routers)
├── routers/
│   ├── __init__.py
│   └── documents.py             # Document ingestion routes
├── services/
│   ├── __init__.py
│   ├── document_service.py      # Business logic for ingestion
│   └── queue_service.py         # LightRAG queue management
├── middleware/
│   ├── __init__.py
│   └── rate_limiter.py          # Mock rate limiting
├── models/
│   ├── __init__.py
│   ├── requests.py              # IngestDocumentRequest
│   └── responses.py             # IngestDocumentResponse
├── dependencies.py              # FastAPI dependencies
├── config.py                    # Settings (file size limits, rate limits)
└── tests/
    ├── integration/
    │   └── test_document_ingestion.py
    ├── fixtures/
    │   ├── sample.pdf
    │   └── sample-metadata.json
    └── conftest.py              # Test fixtures

shared/
├── database/
│   ├── __init__.py
│   └── neo4j_client.py          # Neo4j connection and queries
└── models/
    └── document.py              # Document and ParsedContent models
```

### Component Architecture
[Source: architecture/components.md]

**FastAPI REST API Service Responsibility:**
Unified entry point for document ingestion, handling HTTP requests, authentication, validation, and routing to RAG-Anything/LightRAG services.

**Key Interfaces to Implement:**
- `POST /api/v1/documents/ingest` - Document ingestion with metadata
- `async def ingest_document(file, metadata, entity_types)` - Service layer ingestion
- `async def store_document(doc_data, parsed_content)` - Neo4j storage
- `async def queue_for_lightrag(doc_id)` - Queue document for processing

**Dependencies:**
- RAG-Anything Service (Story 2.1)
- Metadata Schema (Story 2.2)
- Neo4j Database
- LightRAG Service (Epic 3 - placeholder for now)

**Technology Stack:**
- FastAPI for REST API with automatic OpenAPI generation
- Neo4j Python Driver for graph storage
- Python asyncio for queue management
- Pydantic V2 for validation

### API Endpoint Specification
[Source: architecture/components.md, Epic 2 Story 2.3 AC]

**Endpoint:** `POST /api/v1/documents/ingest`

**Request Format:**
```
Content-Type: multipart/form-data

Fields:
- file: <uploaded file> (required)
- metadata: <JSON string> (optional, validated against schema)
- expected_entity_types: <JSON array of strings> (optional)
```

**Request Example:**
```bash
curl -X POST "http://localhost:8000/api/v1/documents/ingest" \
  -H "X-API-Key: test-key-123" \
  -F "file=@document.pdf" \
  -F 'metadata={"author":"John Doe","department":"Engineering","tags":["technical","api"]}' \
  -F 'expected_entity_types=["person","organization","technology"]'
```

**Response Format (202 Accepted):**
```json
{
  "document_id": "550e8400-e29b-41d4-a716-446655440000",
  "filename": "document.pdf",
  "ingestion_status": "parsing",
  "metadata": {
    "author": "John Doe",
    "department": "Engineering",
    "tags": ["technical", "api"]
  },
  "size_bytes": 1048576,
  "ingestion_date": "2025-10-16T14:30:00Z",
  "expected_entity_types": ["person", "organization", "technology"]
}
```

**Response Format (After parsing, status = "queued"):**
```json
{
  "document_id": "550e8400-e29b-41d4-a716-446655440000",
  "filename": "document.pdf",
  "ingestion_status": "queued",
  "metadata": {
    "author": "John Doe",
    "department": "Engineering",
    "tags": ["technical", "api"]
  },
  "size_bytes": 1048576,
  "ingestion_date": "2025-10-16T14:30:00Z",
  "parsed_content_summary": {
    "text_blocks": 25,
    "images": 3,
    "tables": 2
  }
}
```

**Error Response (400 Bad Request - Unsupported Format):**
```json
{
  "error": {
    "code": "UNSUPPORTED_FORMAT",
    "message": "File format .exe is not supported. Supported formats: pdf, txt, md, docx, pptx, csv"
  }
}
```

**Error Response (413 Payload Too Large):**
```json
{
  "error": {
    "code": "FILE_TOO_LARGE",
    "message": "File size exceeds maximum limit of 50MB. Uploaded file size: 75MB"
  }
}
```

**Error Response (422 Unprocessable Entity - Invalid Metadata):**
```json
{
  "error": {
    "code": "INVALID_METADATA",
    "message": "Metadata validation failed",
    "fields": [
      {
        "field": "date_created",
        "error": "Invalid date format. Expected ISO 8601 (YYYY-MM-DD)"
      }
    ]
  }
}
```

**Error Response (429 Too Many Requests - Rate Limit):**
```json
{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Rate limit exceeded. Maximum 10 requests per minute per API key"
  }
}
```

**Response Headers:**
```
X-RateLimit-Limit: 10
X-RateLimit-Remaining: 5
X-RateLimit-Reset: 1697463000
```

### Neo4j Storage Schema
[Source: Epic 2 Story 2.3 AC4]

**Document Node:**
```cypher
CREATE (d:Document {
  id: $document_id,                    // UUID string
  filename: $filename,                 // Original filename
  status: $status,                     // "parsing", "queued", "indexed", "failed"
  metadata: $metadata,                 // JSON object (custom fields from schema)
  ingestion_date: datetime(),          // ISO 8601 datetime
  size_bytes: $size_bytes,             // File size in bytes
  expected_entity_types: $entity_types // Optional list of entity types
})
```

**ParsedContent Node:**
```cypher
CREATE (pc:ParsedContent {
  id: randomUUID(),
  text: $text_blocks,                  // Combined text content
  format: $format,                     // "pdf", "docx", etc.
  tables: $tables,                     // JSON array of table data
  images: $images,                     // JSON array of image references
  equations: $equations,               // JSON array of equations (if any)
  page_count: $page_count              // Number of pages
})
```

**Relationship:**
```cypher
CREATE (d:Document)-[:HAS_CONTENT]->(pc:ParsedContent)
```

**Indexes:**
```cypher
CREATE INDEX document_id_index IF NOT EXISTS FOR (d:Document) ON (d.id);
CREATE INDEX document_metadata_index IF NOT EXISTS FOR (d:Document) ON (d.metadata);
CREATE INDEX document_status_index IF NOT EXISTS FOR (d:Document) ON (d.status);
```

### Document Ingestion Workflow
[Source: architecture/core-workflows.md]

The ingestion workflow orchestrates multiple services:

```
User → FastAPI API → RAG-Anything Service → Neo4j (store) → LightRAG Queue → LightRAG Service (Epic 3)
```

**Ingestion Steps:**
1. Validate file size and format
2. Validate metadata against schema
3. Check rate limits
4. Call RAG-Anything service to parse document
5. Store Document node in Neo4j with status="parsing"
6. Store ParsedContent node in Neo4j
7. Create HAS_CONTENT relationship
8. Update Document status to "queued"
9. Queue document for LightRAG processing (placeholder for Epic 3)
10. Return 202 Accepted with document_id

### Rate Limiting Implementation
[Source: Epic 2 Story 2.3 AC6]

Mock rate limiting for Epic 2 testing:

```python
# services/api/middleware/rate_limiter.py
from typing import Dict
import time
from collections import defaultdict
from fastapi import Request, HTTPException, status

class InMemoryRateLimiter:
    """Mock rate limiter using API key tracking."""

    def __init__(self, max_requests: int = 10, window_seconds: int = 60):
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.requests: Dict[str, list] = defaultdict(list)

    async def check_rate_limit(self, request: Request):
        """Check if request is within rate limit."""
        api_key = request.headers.get("X-API-Key")

        if not api_key:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail={"error": {"code": "MISSING_API_KEY", "message": "API key required"}}
            )

        # Mock validation: accept any non-empty API key
        if len(api_key) < 5:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail={"error": {"code": "INVALID_API_KEY", "message": "Invalid API key"}}
            )

        # Check rate limit
        now = time.time()
        cutoff = now - self.window_seconds
        self.requests[api_key] = [t for t in self.requests[api_key] if t > cutoff]

        if len(self.requests[api_key]) >= self.max_requests:
            raise HTTPException(
                status_code=status.HTTP_429_TOO_MANY_REQUESTS,
                detail={
                    "error": {
                        "code": "RATE_LIMIT_EXCEEDED",
                        "message": f"Rate limit exceeded. Maximum {self.max_requests} requests per minute per API key"
                    }
                }
            )

        self.requests[api_key].append(now)
        return api_key
```

### LightRAG Queue Mechanism
[Source: Epic 2 Story 2.3 AC7]

In-memory asyncio queue for MVP:

```python
# services/api/services/queue_service.py
import asyncio
from typing import Dict, Optional
from uuid import UUID

class LightRAGQueue:
    """In-memory queue for LightRAG document processing."""

    def __init__(self):
        self.queue: asyncio.Queue = asyncio.Queue()
        self.processing: Dict[UUID, str] = {}  # doc_id -> status

    async def enqueue(self, doc_id: UUID, parsed_content: dict, metadata: dict):
        """Add document to LightRAG processing queue."""
        await self.queue.put({
            "doc_id": doc_id,
            "parsed_content": parsed_content,
            "metadata": metadata
        })
        self.processing[doc_id] = "queued"

    async def get_status(self, doc_id: UUID) -> Optional[str]:
        """Get processing status for document."""
        return self.processing.get(doc_id)

    # Note: Processing worker will be implemented in Epic 3
```

### Coding Standards
[Source: architecture/coding-standards.md]

**Critical Rules:**
- **Type Safety:** Use Pydantic V2 for all request/response models; strict type hints
- **Error Handling:** Catch all exceptions and return standardized ApiError responses
- **Async/Await:** All I/O operations (file upload, Neo4j, RAG-Anything calls) must use async
- **Logging:** Use structlog with JSON format; include request_id, doc_id in all logs
- **API Versioning:** All routes prefixed with `/api/v1/`
- **Neo4j Queries:** Always use parameterized Cypher queries; never string interpolation
- **Dependency Injection:** Use FastAPI Depends() for database connections, services

**Naming Conventions:**
- Modules: `snake_case` (e.g., `document_service.py`)
- Classes: `PascalCase` (e.g., `DocumentService`)
- Functions: `snake_case`, async: `async def ingest_document()`
- Constants: `SCREAMING_SNAKE_CASE` (e.g., `MAX_FILE_SIZE_MB`)
- API Routes: `kebab-case` (e.g., `/documents/ingest`)
- Pydantic Models: Suffix with type (e.g., `IngestRequest`, `IngestResponse`)
- JSON Fields: `camelCase` in responses

### Testing Standards
[Source: architecture/testing-strategy.md]

**Testing Requirements:**
- **Integration Tests (services/api/tests/integration/):**
  - Test successful document ingestion with valid metadata
  - Test file size validation (413 error)
  - Test unsupported format validation (400 error)
  - Test metadata validation (422 error)
  - Test rate limiting (429 error)
  - Test Neo4j document storage
  - Test LightRAG queue enqueue
  - Use httpx AsyncClient for API requests
  - Use pytest-asyncio for async test support

**Test File Organization:**
```
services/api/tests/
├── conftest.py                  # Pytest fixtures (client, Neo4j, files)
├── integration/
│   └── test_document_ingestion.py
└── fixtures/
    ├── sample.pdf               # Test PDF file
    ├── sample.txt
    ├── large-file.pdf           # >50MB for size testing
    ├── unsupported.exe          # Unsupported format
    └── metadata-valid.json      # Valid metadata examples
```

**Test Example:**
```python
import pytest
from httpx import AsyncClient
from fastapi import status

@pytest.mark.asyncio
async def test_ingest_document_success(
    async_client: AsyncClient,
    sample_pdf_file: bytes,
    valid_metadata: dict
):
    """Test successful document ingestion with metadata."""
    files = {"file": ("test.pdf", sample_pdf_file, "application/pdf")}
    data = {
        "metadata": json.dumps(valid_metadata),
        "expected_entity_types": json.dumps(["person", "organization"])
    }

    response = await async_client.post(
        "/api/v1/documents/ingest",
        files=files,
        data=data,
        headers={"X-API-Key": "test-key-123"}
    )

    assert response.status_code == status.HTTP_202_ACCEPTED
    result = response.json()
    assert "document_id" in result
    assert result["ingestion_status"] in ["parsing", "queued"]
    assert result["metadata"] == valid_metadata
    assert result["filename"] == "test.pdf"
    assert result["size_bytes"] > 0

@pytest.mark.asyncio
async def test_ingest_file_too_large(
    async_client: AsyncClient,
    large_pdf_file: bytes
):
    """Test file size limit enforcement (413 response)."""
    files = {"file": ("large.pdf", large_pdf_file, "application/pdf")}

    response = await async_client.post(
        "/api/v1/documents/ingest",
        files=files,
        headers={"X-API-Key": "test-key-123"}
    )

    assert response.status_code == status.HTTP_413_REQUEST_ENTITY_TOO_LARGE
    error = response.json()
    assert error["error"]["code"] == "FILE_TOO_LARGE"
    assert "50MB" in error["error"]["message"]

@pytest.mark.asyncio
async def test_rate_limit_exceeded(async_client: AsyncClient, sample_pdf_file: bytes):
    """Test rate limiting after 10 requests."""
    files = {"file": ("test.pdf", sample_pdf_file, "application/pdf")}

    # Make 10 successful requests
    for i in range(10):
        response = await async_client.post(
            "/api/v1/documents/ingest",
            files=files,
            headers={"X-API-Key": "test-key-123"}
        )
        assert response.status_code == status.HTTP_202_ACCEPTED

    # 11th request should be rate limited
    response = await async_client.post(
        "/api/v1/documents/ingest",
        files=files,
        headers={"X-API-Key": "test-key-123"}
    )

    assert response.status_code == status.HTTP_429_TOO_MANY_REQUESTS
    error = response.json()
    assert error["error"]["code"] == "RATE_LIMIT_EXCEEDED"
```

### Previous Story Insights
[Source: docs/stories/2.1.integrate-rag-anything.md, docs/stories/2.2.metadata-schema.md]

**Relevant Learnings from Story 2.1:**
- RAG-Anything service exposes `/parse` endpoint for document parsing
- Parsing returns content_list with text blocks, images, tables, equations
- Handle parsing failures gracefully with error responses
- Use async HTTP client (httpx) for inter-service communication

**Relevant Learnings from Story 2.2:**
- Metadata validation uses Pydantic models from `shared/models/metadata.py`
- Use FastAPI dependency injection for metadata schema
- Return 422 for validation failures with field-specific errors
- Apply default values for missing optional fields

**Technical Patterns to Follow:**
- Use FastAPI dependency injection for shared resources (Neo4j, services)
- Implement service layer for business logic (separate from routers)
- Return appropriate HTTP status codes (202, 400, 413, 422, 429)
- Include request_id in all structured logs
- Use parameterized Neo4j queries to prevent injection

---

## Testing

### Test File Locations
[Source: architecture/testing-strategy.md]

**Integration Tests:**
- `services/api/tests/integration/test_document_ingestion.py` - API endpoint tests
- `services/api/tests/conftest.py` - Pytest fixtures

**Test Fixtures:**
- `services/api/tests/fixtures/sample.pdf` - Valid PDF file
- `services/api/tests/fixtures/sample.txt` - Valid text file
- `services/api/tests/fixtures/large-file.pdf` - >50MB file for size testing
- `services/api/tests/fixtures/unsupported.exe` - Unsupported format
- `services/api/tests/fixtures/metadata-valid.json` - Valid metadata examples

### Testing Approach
[Source: architecture/testing-strategy.md]

1. **Unit Tests (30%)**: Test service layer functions in isolation with mocks
2. **Integration Tests (60%)**: Test API endpoints with real HTTP requests and Neo4j
3. **E2E Tests (10%)**: Test full workflow (Epic 3 - after LightRAG integration)
4. **Coverage Target**: 80%+ for routers and services

### Required Test Scenarios
- Successful PDF ingestion with metadata (202 response)
- Successful TXT ingestion without metadata (202 response)
- File size limit enforcement (413 response)
- Unsupported file format (400 response)
- Invalid metadata (422 response)
- Missing API key (401 response)
- Rate limit exceeded (429 response)
- Neo4j document node creation
- Neo4j parsed content node creation
- LightRAG queue enqueue
- OpenAPI schema validation

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-16 | 1.0 | Story created from Epic 2 | Sarah (PO Agent) |

---

## Dev Agent Record

### Agent Model Used
*[To be populated by Dev Agent during implementation]*

### Debug Log References
*[To be populated by Dev Agent during implementation]*

### Completion Notes
*[To be populated by Dev Agent during implementation]*

### File List
*[To be populated by Dev Agent during implementation]*

---

## QA Results
*[To be populated by QA Agent after implementation]*
