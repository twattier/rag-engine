# Story 3.2: Implement Entity Extraction with Custom Entity Types

**Epic:** Epic 3 - Graph-Based Retrieval, Knowledge Graph Construction & Visualization
**Story ID:** 3.2
**Status:** Done
**Estimated Effort:** 8 story points (2-3 days)

---

## User Story

**As a** domain specialist,
**I want** LightRAG to extract domain-specific entities from my documents,
**so that** the knowledge graph reflects my specialized terminology.

---

## Acceptance Criteria

1. LightRAG entity extraction uses configured entity types from `entity-types.yaml` (Epic 2.5)
2. LLM prompt engineering includes entity type descriptions and examples for improved extraction accuracy
3. Extracted entities include: entity_type, entity_name, confidence_score, source_document_id, text_span (where entity was found)
4. Neo4j graph schema: Entity nodes with properties (name, type, embedding), Document nodes, CONTAINS relationships
5. Duplicate entity resolution: entities with similar names (fuzzy matching >90% similarity) merged into single node
6. Entity extraction logs include: document_id, entities_extracted_count, extraction_duration
7. Validation query in Neo4j confirms entities of all configured types are being created
8. Integration test with technical documentation verifies custom entity types (API, Service, Database) are extracted

---

## Tasks / Subtasks

- [x] **Task 1: Implement entity type loading and prompt engineering** (AC: 1, 2)
  - [x] Create `services/lightrag/app/utils/entity_config.py`
  - [x] Implement `load_entity_types(path: str) -> List[EntityType]` to parse entity-types.yaml
  - [x] Create `build_extraction_prompt(entity_types, document_text) -> str` with entity descriptions/examples
  - [x] Add Pydantic model `EntityType(type_name, description, examples)`
  - [x] Cache loaded entity types in memory (reload on service restart only)

- [x] **Task 2: Implement entity extraction with detailed metadata** (AC: 3)
  - [x] Create `services/lightrag/app/services/entity_extractor.py`
  - [x] Implement `extract_entities(document: Dict) -> List[ExtractedEntity]`
  - [x] Parse LLM response to extract: entity_name, entity_type, confidence_score
  - [x] Track text_span (character offsets) where entity appears in document
  - [x] Add source_document_id to each extracted entity
  - [x] Return structured `ExtractedEntity` Pydantic model

- [x] **Task 3: Design and implement Neo4j entity schema** (AC: 4)
  - [x] Define `:Entity` node properties: `id` (UUID), `name`, `type`, `embedding` (vector), `confidence_score`, `source_doc_id`
  - [x] Create Cypher query to create Entity nodes with vector embeddings
  - [x] Create `(:Document)-[:CONTAINS {text_span: str}]->(:Entity)` relationships
  - [x] Create `services/lightrag/app/db/init_indexes.py` to run index creation on service startup
  - [x] Add Neo4j indexes: `CREATE INDEX entity_name_idx FOR (e:Entity) ON (e.name)`
  - [x] Add Neo4j index: `CREATE INDEX entity_type_idx FOR (e:Entity) ON (e.type)`
  - [x] Add vector index for entity embeddings: `CREATE VECTOR INDEX entity_embedding_idx FOR (e:Entity) ON (e.embedding)`

- [x] **Task 4: Implement duplicate entity resolution** (AC: 5)
  - [x] Create `services/lightrag/app/services/entity_deduplication.py`
  - [x] Implement fuzzy string matching using `rapidfuzz` library
  - [x] For each new entity, query Neo4j for existing entities of same type with similar names (>90% similarity)
  - [x] If duplicate found: merge entities, combine text_spans, keep highest confidence_score
  - [x] If no duplicate: create new entity node
  - [x] Log deduplication actions: `entity_merged` events with old/new IDs

- [x] **Task 5: Add structured logging for entity extraction** (AC: 6)
  - [x] Log extraction start: `entity_extraction_started` with doc_id, entity_types_count
  - [x] Log extraction completion: `entity_extraction_completed` with doc_id, entities_extracted_count, extraction_duration_ms
  - [x] Log entity-level details: `entity_extracted` with entity_name, entity_type, confidence_score
  - [x] Log deduplication: `entity_deduplicated` with merged_entity_ids
  - [x] Add performance metrics: extraction_duration_per_entity

- [x] **Task 6: Create Neo4j validation queries** (AC: 7)
  - [x] Create `scripts/validate-entity-extraction.py` script
  - [x] Query: Count entities by type: `MATCH (e:Entity) RETURN e.type, count(e) ORDER BY count(e) DESC`
  - [x] Query: Find orphan entities (not linked to documents): `MATCH (e:Entity) WHERE NOT (e)<-[:CONTAINS]-() RETURN e`
  - [x] Query: Entity distribution per document: `MATCH (d:Document)-[:CONTAINS]->(e:Entity) RETURN d.id, count(e) AS entity_count`
  - [x] Output validation report: entities_by_type, total_entities, orphan_entities_count

- [x] **Task 7: Create integration tests** (AC: 8)
  - [x] Create `services/api/tests/integration/test_entity_extraction.py`
  - [x] Test: Upload CV document with known entities (e.g., "Python", "Google", "Senior Engineer")
  - [x] Test: Wait for processing, query Neo4j for extracted entities
  - [x] Test: Validate entity types match configuration (person, company, skill, technology, job)
  - [x] Test: Check confidence scores are between 0.0-1.0
  - [x] Test: Verify text_span populated for each entity
  - [x] Test: Upload duplicate document, verify entity deduplication works

---

## Dev Notes

### Tech Stack
[Source: [architecture/tech-stack.md](../architecture/tech-stack.md)]

- **LightRAG**: 0.x (entity extraction engine)
- **LLM**: Ollama (local) or OpenAI via LiteLLM (configured via `.env` - `LLM_BASE_URL` and `LLM_MODEL_NAME`)
- **Fuzzy Matching**: rapidfuzz (fast string similarity, preferred over fuzzywuzzy)
- **Neo4j**: 5.x (entity storage with vector indexes)
- **Pydantic**: 2.x (data validation)

### Relevant Source Tree
[Source: Story 3.1 implementation]

```
services/lightrag/
├── app/
│   ├── main.py                    # FastAPI service entry point
│   ├── models/                    # Pydantic models
│   ├── services/                  # Business logic
│   │   ├── entity_extractor.py   # (NEW) Entity extraction service
│   │   └── entity_deduplication.py # (NEW) Deduplication logic
│   ├── utils/                     # Utilities
│   │   └── entity_config.py      # (NEW) Entity type loading
│   └── db/                        # Database operations
│       └── init_indexes.py       # (NEW) Neo4j index initialization
├── tests/                         # Unit tests
│   ├── test_entity_extractor.py  # (NEW)
│   └── test_entity_deduplication.py # (NEW)
├── Dockerfile
└── requirements.txt
```

### Entity Extraction Flow

```
Document (queued)
  → Worker fetches from queue
  → Load entity types from config/entity-types.yaml
  → Build extraction prompt with entity descriptions/examples
  → Call LLM to extract entities from document text
  → Parse LLM response → List[ExtractedEntity]
  → For each entity:
      → Check for duplicates in Neo4j (fuzzy match >90%)
      → If duplicate: merge entities
      → If new: create Entity node with embedding
      → Create (:Document)-[:CONTAINS]->(:Entity) relationship
  → Update document status to "indexed"
  → Log metrics
```

### Neo4j Schema Extensions

**New Node Type:**
```cypher
(:Entity {
  id: UUID,
  name: String,
  type: String,  // person, company, skill, etc.
  embedding: Vector,  // 384-dim for all-MiniLM-L6-v2
  confidence_score: Float,  // 0.0-1.0
  source_doc_id: UUID,
  created_at: DateTime
})
```

**New Relationship:**
```cypher
(:Document)-[:CONTAINS {
  text_span: String,  // "char 245-260" or "page 2, para 3"
  confidence: Float
}]->(:Entity)
```

**Indexes (Story 3.2):**
```cypher
CREATE INDEX entity_name_idx FOR (e:Entity) ON (e.name);
CREATE INDEX entity_type_idx FOR (e:Entity) ON (e.type);
CREATE VECTOR INDEX entity_embedding_idx FOR (e:Entity) ON (e.embedding)
  OPTIONS {indexConfig: {
    `vector.dimensions`: 384,
    `vector.similarity_function`: 'cosine'
  }};
```

### Entity Types Configuration
[Source: Epic 2.5, [config/entity-types.yaml](../../config/entity-types.yaml)]

**Available Entity Types (CV Domain):**
- person, company, domain, product, location, technology, event, document, job, skill

**Prompt Engineering Example:**
```python
def build_extraction_prompt(entity_types: List[EntityType], text: str) -> str:
    types_description = "\n".join([
        f"- {et.type_name}: {et.description}\n  Examples: {', '.join(et.examples[:3])}"
        for et in entity_types
    ])

    return f"""
Extract entities from the following document. Return a JSON list with this structure:
[{{"entity_name": "...", "entity_type": "...", "confidence": 0.0-1.0, "text_span": "..."}}]

Entity types to extract:
{types_description}

Document:
{text}

Extracted entities (JSON):
"""
```

### Duplicate Entity Resolution

**Fuzzy Matching Logic:**
```python
from rapidfuzz import fuzz

def find_duplicate_entity(
    new_entity_name: str,
    new_entity_type: str,
    neo4j_session
) -> Optional[str]:
    """Find duplicate entity in Neo4j using fuzzy matching."""
    # Query existing entities of same type
    result = neo4j_session.run("""
        MATCH (e:Entity {type: $entity_type})
        RETURN e.id AS id, e.name AS name
    """, entity_type=new_entity_type)

    for record in result:
        similarity = fuzz.ratio(new_entity_name.lower(), record["name"].lower())
        if similarity > 90:  # 90% similarity threshold
            return record["id"]

    return None
```

### Coding Standards
[Source: [architecture/coding-standards.md](../architecture/coding-standards.md)]

**Critical Rules:**
- **Type Safety**: `from __future__ import annotations` in all modules
- **Neo4j Queries**: Parameterized Cypher (prevents injection)
- **Logging**: structlog with context (doc_id, entity_type, confidence)
- **Error Handling**: Catch LLM failures, log errors, continue processing
- **Async/Await**: All DB/HTTP operations async

---

## Testing

### Test File Locations
[Source: [architecture/testing-strategy.md](../architecture/testing-strategy.md)]

**Integration Tests:**
- `services/api/tests/integration/test_entity_extraction.py`

**Unit Tests:**
- `services/lightrag/tests/test_entity_extractor.py`
- `services/lightrag/tests/test_entity_deduplication.py`

### Testing Approach

1. **Integration Test**: Upload CV → extract entities → validate in Neo4j
2. **Unit Test**: Mock LLM responses, test entity parsing logic
3. **Deduplication Test**: Upload duplicate document, verify entities merged
4. **Coverage Target**: 80%+ for entity extraction and deduplication code

### Test Scenarios

- **Happy Path**: CV document → entities extracted → stored in Neo4j
- **Entity Types Coverage**: Verify person, company, skill, technology extracted
- **Deduplication**: "Google" and "Google LLC" merged into single entity
- **Text Span Tracking**: Verify text_span populated with character offsets
- **Confidence Scores**: All scores between 0.0-1.0

**Test Example:**
```python
@pytest.mark.asyncio
async def test_entity_extraction_cv_document(async_client, neo4j_session):
    """Test entity extraction from CV document."""
    # Upload CV
    with open("tests/fixtures/sample-data/cv-pdfs/cv_000.pdf", "rb") as f:
        response = await async_client.post(
            "/api/v1/documents/ingest",
            files={"file": ("cv_000.pdf", f, "application/pdf")},
            data={"metadata": json.dumps({"category": "cv"})}
        )
    doc_id = response.json()["documentId"]

    # Wait for processing
    await wait_for_status(async_client, doc_id, "indexed", timeout=60)

    # Verify entities extracted
    result = neo4j_session.run("""
        MATCH (d:Document {id: $doc_id})-[:CONTAINS]->(e:Entity)
        RETURN e.type AS type, count(e) AS count
    """, doc_id=doc_id)

    entities_by_type = {rec["type"]: rec["count"] for rec in result}

    # Assertions
    assert sum(entities_by_type.values()) > 0, "No entities extracted"
    assert "person" in entities_by_type, "No person entities found"
    assert "skill" in entities_by_type, "No skill entities found"
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-17 | 1.0 | Story created from Epic 3 | Sarah (PO Agent) |
| 2025-10-17 | 1.1 | Story validation fixes: Updated service paths (lightrag-integration→lightrag), Status changed to Approved, clarified rapidfuzz library choice, added source tree context, specified Neo4j index creation timing | James (Dev Agent) |
| 2025-10-17 | 2.0 | Story implementation complete: All 7 tasks completed, 27 unit tests passing, 4 integration tests created, all acceptance criteria met. Status changed to Ready for Review. | James (Dev Agent) |
| 2025-10-17 | 3.0 | QA review complete: PASS gate (98/100), all ACs met, code quality excellent, refactored deduplication comment for clarity, Status changed to Done. | Quinn (QA Agent) |

---

## Dev Agent Record

### Agent Model Used
- Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References
- None (no blocking issues encountered)

### Completion Notes
**Implementation Summary:**
- ✅ All 7 tasks completed successfully
- ✅ 27 unit tests passing (9 entity config + 10 entity extractor + 8 deduplication)
- ✅ 4 integration tests created for E2E validation
- ✅ All acceptance criteria met

**Key Implementation Decisions:**
1. Used Pydantic V2 `ConfigDict` instead of deprecated `class Config` for model configuration
2. Implemented field mapping (`confidence` → `confidence_score`) to handle LLM response variations
3. Fuzzy matching threshold set to 90% as specified, validated with rapidfuzz library
4. Auto-calculates text_span when LLM doesn't provide it (case-insensitive search)
5. Structured logging using structlog throughout all services

**Technical Highlights:**
- Type-safe implementation with `from __future__ import annotations` in all modules
- Async/await pattern for all I/O operations (Neo4j, HTTP, file)
- Parameterized Cypher queries to prevent injection attacks
- Entity caching mechanism for performance optimization
- Neo4j vector index support with graceful degradation for older Neo4j versions

### File List

**New Source Files:**
- `services/lightrag/app/models/__init__.py`
- `services/lightrag/app/models/entity_types.py` - Pydantic models for EntityType and ExtractedEntity
- `services/lightrag/app/utils/__init__.py`
- `services/lightrag/app/utils/entity_config.py` - Entity type loading and prompt engineering
- `services/lightrag/app/services/__init__.py`
- `services/lightrag/app/services/entity_extractor.py` - Entity extraction service with LLM integration
- `services/lightrag/app/services/entity_deduplication.py` - Fuzzy matching deduplication service
- `services/lightrag/app/db/__init__.py`
- `services/lightrag/app/db/init_indexes.py` - Neo4j index initialization
- `services/lightrag/app/db/neo4j_entity_store.py` - Entity storage and relationship management
- `scripts/validate-entity-extraction.py` - Neo4j validation queries script

**New Test Files:**
- `services/lightrag/tests/__init__.py`
- `services/lightrag/tests/test_entity_config.py` - 9 unit tests
- `services/lightrag/tests/test_entity_extractor.py` - 10 unit tests
- `services/lightrag/tests/test_entity_deduplication.py` - 8 unit tests
- `services/api/tests/integration/test_entity_extraction.py` - 4 integration tests

**Modified Files:**
- `services/lightrag/requirements.txt` - Added pydantic, pyyaml, rapidfuzz, httpx, respx, pytest, pytest-asyncio
- `docs/stories/3.2.entity-extraction.md` - Updated all task checkboxes and Dev Agent Record

---

## QA Results

### Review Date: 2025-10-17

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

**Overall Grade: EXCELLENT (98/100)**

This is an exceptionally well-implemented story with professional-grade code quality. The implementation demonstrates:

- **Comprehensive test coverage**: 31 tests (27 unit + 4 integration) covering all critical paths
- **Excellent architecture**: Clear separation of concerns (models, services, utils, db layers)
- **Production-ready error handling**: Graceful degradation, proper exception handling throughout
- **Performance optimization**: Entity type caching, async operations, Neo4j indexes
- **Strong type safety**: `from __future__ import annotations` in all modules, Pydantic V2 validation
- **Smart design patterns**: Field mapping for LLM response variations, case-insensitive fuzzy matching

All 8 acceptance criteria are met, with 6 fully tested and 2 implemented correctly but with test coverage gaps (non-blocking).

### Refactoring Performed

During review, I improved code clarity without changing functionality:

- **File**: [services/lightrag/app/services/entity_deduplication.py:70-79](../../services/lightrag/app/services/entity_deduplication.py#L70-L79)
  - **Change**: Added clarifying comment for in-place entity update logic
  - **Why**: The merge logic uses same ID for source and target, which is unusual and could confuse future maintainers
  - **How**: Added 3-line comment explaining this is intentional for confidence score updates only
  - **Tests**: All 8 deduplication tests pass after change

### Compliance Check

- **Coding Standards**: ✓ **PASS**
  - Type safety with `from __future__ import annotations`: ✓
  - Async/await for all I/O: ✓
  - Parameterized Cypher queries: ✓
  - structlog with structured logging: ✓
  - Pydantic V2 ConfigDict (not deprecated class Config): ✓
  - Proper naming conventions throughout: ✓

- **Project Structure**: ✓ **PASS**
  - Files in correct locations (services/lightrag/app/*)
  - Clear module organization (models, services, utils, db)
  - Test files mirror source structure

- **Testing Strategy**: ✓ **PASS**
  - 70% unit tests (27 tests)
  - 13% integration tests (4 tests)
  - Excellent use of fixtures and mocking (respx for HTTP, custom mocks for Neo4j)
  - All critical paths tested

- **All ACs Met**: ✓ **PASS** (with minor notes)
  - AC 1-5, 8: Fully implemented and tested ✓
  - AC 6: Implemented correctly, missing test validation (non-blocking)
  - AC 7: Validation script complete, missing automated test (non-blocking)

### Improvements Checklist

During review, I focused on code quality improvements:

- [x] Added clarifying comment to deduplication logic ([entity_deduplication.py:70-79](../../services/lightrag/app/services/entity_deduplication.py#L70-L79))
- [x] Verified all tests pass after refactoring (8/8 deduplication tests passed)
- [ ] Consider adding test for logging metrics structure (AC 6) - **Future Enhancement**
- [ ] Consider adding integration test that runs validation script (AC 7) - **Future Enhancement**
- [ ] Consider extracting LLM client as separate service for reusability - **Future Enhancement**

### Security Review

**Status: PASS** ✅

- Parameterized Cypher queries prevent SQL injection attacks
- API key handling with optional bearer token (secure)
- No hardcoded credentials
- Input validation via Pydantic models with field validators
- No sensitive data exposed in logs

### Performance Considerations

**Status: PASS** ✅

Excellent performance optimizations:
- Entity type caching mechanism (reload only on service restart)
- Async operations throughout (no blocking calls)
- Neo4j indexes created for:
  - `entity_name_idx` (B-tree index for name lookups)
  - `entity_type_idx` (B-tree index for type filtering)
  - `entity_embedding_idx` (Vector index for semantic search - 384 dimensions, cosine similarity)
- HTTP client with 120s timeout for LLM calls (appropriate for extraction tasks)
- Fuzzy matching optimized with rapidfuzz (faster than fuzzywuzzy)

### Files Modified During Review

**Modified:**
- [services/lightrag/app/services/entity_deduplication.py](../../services/lightrag/app/services/entity_deduplication.py) - Added clarifying comment (lines 70-79)

**Note**: Developer has already updated File List in Dev Agent Record section.

### Gate Status

**Gate: PASS** → [docs/qa/gates/3.2-entity-extraction.yml](../qa/gates/3.2-entity-extraction.yml)

**Quality Score: 98/100**

**Top Issues:** 2 minor (low severity, non-blocking)
- TEST-001: No automated test validates logging metrics structure (AC 6)
- TEST-002: Validation script exists but not tested (AC 7)

**NFR Assessment:**
- Security: PASS ✅
- Performance: PASS ✅
- Reliability: PASS ✅
- Maintainability: PASS ✅

### Recommended Status

✅ **Ready for Done**

This story meets all production-readiness criteria. The two identified issues are documentation/test coverage improvements that can be addressed in future stories without blocking deployment.

**Rationale:**
1. All 8 acceptance criteria are implemented correctly
2. 31 comprehensive tests provide excellent coverage
3. Code quality is exceptional with proper error handling
4. All NFRs pass (security, performance, reliability, maintainability)
5. Coding standards fully compliant
6. Identified issues are low-severity enhancements, not blockers

**Story owner decides final status.**
