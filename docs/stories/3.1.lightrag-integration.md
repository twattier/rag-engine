# Story 3.1: Integrate LightRAG Core Library and Initialize Graph Storage

**Epic:** Epic 3 - Graph-Based Retrieval, Knowledge Graph Construction & Visualization
**Story ID:** 3.1
**Status:** Draft
**Estimated Effort:** 8 story points (2-3 days)

---

## User Story

**As a** developer,
**I want** LightRAG integrated with Neo4j for graph-based knowledge representation,
**so that** documents are transformed into entity-relationship graphs.

---

## Acceptance Criteria

1. `services/lightrag-integration/` contains LightRAG integration service
2. Service initializes LightRAG instance with Neo4j storage backend configuration
3. LightRAG configuration includes: Neo4j connection parameters, embedding model (sentence-transformers), LLM endpoint (via LiteLLM or direct)
4. Service exposes internal API endpoint `POST /build-graph` accepting parsed document content from RAG-Anything service
5. Graph construction extracts entities based on configured entity types (from Epic 2.5)
6. Extracted entities and relationships persisted to Neo4j with vector embeddings
7. `shared/utils/lightrag_client.py` provides reusable LightRAG client wrapper
8. Integration test verifies graph construction for sample document, validates entities exist in Neo4j

---

## Tasks / Subtasks

- [ ] **Task 1: Set up LightRAG service structure** (AC: 1, 2, 3)
  - [ ] Review existing `services/lightrag/` stub and determine if usable
  - [ ] Create `services/lightrag-integration/` directory structure (or refactor stub)
  - [ ] Create `services/lightrag-integration/app/main.py` - FastAPI service entry point
  - [ ] Create `services/lightrag-integration/app/config.py` - LightRAG configuration using Pydantic Settings
  - [ ] Create `services/lightrag-integration/Dockerfile` with LightRAG dependencies
  - [ ] Create `services/lightrag-integration/requirements.txt` with: lightrag, sentence-transformers, neo4j, fastapi, uvicorn
  - [ ] Add LightRAG service to `docker-compose.yml` with Neo4j connection env vars

- [ ] **Task 2: Initialize LightRAG with Neo4j storage backend** (AC: 2, 3)
  - [ ] Create `services/lightrag-integration/app/services/lightrag_service.py`
  - [ ] Implement LightRAG initialization with Neo4j storage adapter
  - [ ] Configure embedding model (sentence-transformers default, configurable via .env)
  - [ ] Configure LLM endpoint (LiteLLM proxy or direct OpenAI/Ollama, configurable)
  - [ ] Load entity types from `config/entity-types.yaml` for entity extraction prompts
  - [ ] Add health check endpoint `GET /health` to verify LightRAG + Neo4j connection

- [ ] **Task 3: Implement queue processing worker** (AC: 4, 5, 6)
  - [ ] Create `services/api/app/workers/lightrag_worker.py` - background worker
  - [ ] Implement `process_documents()` function to consume from queue (Epic 2 queue service)
  - [ ] For each queued document:
    - [ ] Fetch document from Neo4j (id, parsed_content, metadata)
    - [ ] Call LightRAG to extract entities and relationships
    - [ ] Persist entities as `:Entity` nodes in Neo4j with vector embeddings
    - [ ] Create `(:Document)-[:CONTAINS]->(:Entity)` relationships
    - [ ] Update document status from "queued" → "indexed"
  - [ ] Add error handling: mark document as "failed" on exceptions, log errors
  - [ ] Start worker as background task in FastAPI lifespan

- [ ] **Task 4: Create internal API endpoint** (AC: 4)
  - [ ] Create `services/lightrag-integration/app/routers/graph.py`
  - [ ] Implement `POST /build-graph` endpoint accepting: doc_id, parsed_content, metadata
  - [ ] Call LightRAG service to extract entities and relationships
  - [ ] Return: entities_extracted_count, relationships_count, processing_duration
  - [ ] Add OpenAPI documentation with request/response schemas

- [ ] **Task 5: Create shared LightRAG client wrapper** (AC: 7)
  - [ ] Create `shared/utils/lightrag_client.py` - reusable client for API service
  - [ ] Implement async HTTP client for calling LightRAG service endpoints
  - [ ] Add methods: `build_graph(doc_id, content, metadata)`, `health_check()`
  - [ ] Add retry logic with exponential backoff (3 retries, max 10s timeout)
  - [ ] Add structured logging for all client calls

- [ ] **Task 6: Create integration tests** (AC: 8)
  - [ ] Create `services/api/tests/integration/test_lightrag_integration.py`
  - [ ] Test: Upload sample CV document via ingestion API
  - [ ] Test: Wait for queue processing (poll document status until "indexed")
  - [ ] Test: Query Neo4j for `:Entity` nodes linked to document
  - [ ] Test: Validate entities of configured types exist (person, company, skill, etc.)
  - [ ] Test: Verify `(:Document)-[:CONTAINS]->(:Entity)` relationships created
  - [ ] Add cleanup logic: delete test documents after each test

- [ ] **Task 7: Update docker-compose configuration** (AC: 1, 2, 3)
  - [ ] Add `lightrag-integration` service to docker-compose.yml
  - [ ] Configure environment variables: NEO4J_URI, EMBEDDING_MODEL, LLM_ENDPOINT, ENTITY_TYPES_PATH
  - [ ] Add health check: `curl -f http://localhost:<port>/health`
  - [ ] Add service dependencies: `depends_on: neo4j, litellm (optional)`
  - [ ] Configure internal network for API → LightRAG communication

---

## Dev Notes

### Tech Stack
[Source: [architecture/tech-stack.md](../architecture/tech-stack.md)]

- **LightRAG**: 0.x (graph-based retrieval engine, entity extraction, multi-hop reasoning)
- **Neo4j**: 5.x (graph + vector storage, LightRAG requirement)
- **sentence-transformers**: Latest (local embeddings for MVP, no API costs)
- **LiteLLM**: Latest (unified LLM interface for entity extraction, optional)
- **FastAPI**: 0.115+ (service framework)
- **Uvicorn**: Latest (ASGI server)

### Project Structure

```
rag-engine/
├── services/
│   ├── lightrag-integration/           # NEW - LightRAG service
│   │   ├── app/
│   │   │   ├── main.py                 # FastAPI entry point
│   │   │   ├── config.py               # LightRAG configuration
│   │   │   ├── services/
│   │   │   │   └── lightrag_service.py # LightRAG wrapper
│   │   │   └── routers/
│   │   │       └── graph.py            # /build-graph endpoint
│   │   ├── Dockerfile
│   │   └── requirements.txt
│   └── api/
│       └── app/
│           └── workers/
│               └── lightrag_worker.py  # NEW - Queue processing worker
├── shared/utils/
│   └── lightrag_client.py              # NEW - Reusable client
├── config/
│   └── entity-types.yaml               # EXISTS - From Epic 2.5
└── tests/
    └── integration/
        └── test_lightrag_integration.py # NEW - Integration tests
```

### Epic 2 Handoff Context
[Source: [docs/stories/epic-2-ingestion.md](epic-2-ingestion.md)]

**Queue Service Ready:**
- File: [services/api/app/services/queue_service.py](../../services/api/app/services/queue_service.py)
- 5 CV documents currently in "queued" status waiting for processing
- In-memory asyncio queue (MVP) - may upgrade to Redis in Epic 5

**Entity Types Configured:**
- File: [config/entity-types.yaml](../../config/entity-types.yaml)
- 10 CV-specific types: person, company, domain, product, location, technology, event, document, job, skill
- Each type includes description and examples for LLM prompts

**Neo4j Schema (Epic 2):**
- `(:Document)` nodes with metadata_json field (JSON string)
- `(:ParsedContent)` nodes with text, tables, images
- `(:Document)-[:HAS_CONTENT]->(:ParsedContent)` relationships

**Neo4j Schema Extensions (Epic 3.1):**
- `(:Entity {name, type, embedding})` nodes - NEW
- `(:Document)-[:CONTAINS]->(:Entity)` relationships - NEW

### LightRAG Configuration

**Initialization Example:**
```python
from lightrag import LightRAG
from lightrag.storage import Neo4jStorage

# Initialize Neo4j storage backend
storage = Neo4jStorage(
    uri=settings.NEO4J_URI,
    user="neo4j",
    password=settings.NEO4J_PASSWORD,
    database=settings.NEO4J_DATABASE
)

# Initialize LightRAG instance
lightrag = LightRAG(
    working_dir="./lightrag_cache",  # Local cache directory
    llm=settings.LLM_ENDPOINT,       # LiteLLM proxy or direct
    embedding=settings.EMBEDDING_MODEL,  # sentence-transformers model
    storage=storage,
    entity_types=load_entity_types()  # From config/entity-types.yaml
)
```

**Environment Variables (.env):**
```bash
# LightRAG Configuration
LIGHTRAG_SERVICE_PORT=9300
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
LLM_ENDPOINT=http://litellm:4000/v1  # or http://ollama:11434/v1
ENTITY_TYPES_PATH=config/entity-types.yaml

# Neo4j Configuration (already exists from Epic 1)
NEO4J_URI=bolt://neo4j:7687
NEO4J_AUTH=neo4j/your_secure_password_here
NEO4J_DATABASE=neo4j
```

### Queue Processing Worker Pattern

**Worker Implementation:**
```python
# services/api/app/workers/lightrag_worker.py

import asyncio
from shared.utils.logging import get_logger
from app.services.queue_service import queue_service
from shared.utils.lightrag_client import LightRAGClient
from shared.database.document_repository import DocumentRepository

logger = get_logger(__name__)

async def process_documents():
    """Background worker to process queued documents."""
    lightrag_client = LightRAGClient()
    doc_repo = DocumentRepository()

    while True:
        try:
            # Get document from queue
            item = await queue_service.queue.get()
            doc_id = item["doc_id"]

            logger.info("processing_document", doc_id=doc_id)

            # Fetch document from Neo4j
            document = await doc_repo.get_document(doc_id)

            # Call LightRAG to build graph
            result = await lightrag_client.build_graph(
                doc_id=doc_id,
                content=item["parsed_content"],
                metadata=item["metadata"]
            )

            # Update document status
            await doc_repo.update_status(doc_id, "indexed")

            logger.info(
                "document_processed",
                doc_id=doc_id,
                entities_count=result["entities_count"],
                relationships_count=result["relationships_count"]
            )

        except Exception as e:
            logger.error("document_processing_failed", doc_id=doc_id, error=str(e))
            await doc_repo.update_status(doc_id, "failed")
        finally:
            queue_service.queue.task_done()
```

**Start Worker in FastAPI Lifespan:**
```python
# services/api/app/main.py

from contextlib import asynccontextmanager
import asyncio

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Start background worker
    worker_task = asyncio.create_task(process_documents())
    yield
    # Shutdown: cancel worker
    worker_task.cancel()

app = FastAPI(lifespan=lifespan)
```

### Coding Standards
[Source: [architecture/coding-standards.md](../architecture/coding-standards.md)]

**Critical Rules:**
- **Type Safety**: Use `from __future__ import annotations` and strict type hints in all modules
- **Async/Await**: All I/O operations (DB, HTTP, file) must use async; never block event loop
- **Error Handling**: Catch exceptions, return standardized errors, log with context
- **Logging**: Use structlog with JSON format; include request_id, doc_id in all log entries
- **Neo4j Queries**: Always parameterized Cypher queries (prevents injection)
- **API Versioning**: All routes prefixed with `/api/v1/` (even internal APIs for consistency)
- **Dependency Injection**: Use FastAPI `Depends()` for shared resources

**Naming Conventions:**
- Async functions: `async def aquery()` (prefix with 'a' for LightRAG compatibility)
- Pydantic models: Suffix with type (e.g., `BuildGraphRequest`, `GraphResponse`)
- Neo4j labels: PascalCase (`:Entity`, `:Document`)

---

## Testing

### Test File Locations
[Source: [architecture/testing-strategy.md](../architecture/testing-strategy.md)]

**Integration Tests:**
- `services/api/tests/integration/test_lightrag_integration.py` - Queue processing workflow
- `services/lightrag-integration/tests/test_lightrag_service.py` - LightRAG service unit tests

**Test Fixtures:**
- Use existing CV PDF fixtures from Epic 2: `tests/fixtures/sample-data/cv-pdfs/cv_000.pdf`

### Testing Approach

1. **Integration Test**: Upload CV → verify queue processing → check Neo4j entities
2. **Coverage Target**: 80%+ coverage for worker and LightRAG client code
3. **Performance Baseline**: Log processing time for 1 CV document (target: <30s for entity extraction)

### Test Scenarios Covered

- **Happy Path**: Document queued → processed → status "indexed" → entities in Neo4j
- **Error Handling**: LightRAG service down → document marked "failed"
- **Entity Validation**: All configured entity types extracted (person, company, skill, etc.)
- **Relationship Validation**: `(:Document)-[:CONTAINS]->(:Entity)` relationships created

**Test Example:**
```python
@pytest.mark.asyncio
async def test_queue_processing_workflow(async_client, neo4j_session):
    """Test document queue processing extracts entities."""
    # Step 1: Upload CV document (triggers queue)
    with open("tests/fixtures/sample-data/cv-pdfs/cv_000.pdf", "rb") as f:
        response = await async_client.post(
            "/api/v1/documents/ingest",
            files={"file": ("cv_000.pdf", f, "application/pdf")},
            data={"metadata": json.dumps({"category": "cv"})}
        )
    assert response.status_code == 202
    doc_id = response.json()["documentId"]

    # Step 2: Wait for processing (poll status)
    for _ in range(30):  # Max 60s timeout
        doc = await async_client.get(f"/api/v1/documents/{doc_id}")
        if doc.json()["status"] == "indexed":
            break
        await asyncio.sleep(2)
    else:
        pytest.fail("Processing timeout")

    # Step 3: Verify entities exist in Neo4j
    result = neo4j_session.run("""
        MATCH (d:Document {id: $doc_id})-[:CONTAINS]->(e:Entity)
        RETURN e.type AS entity_type, count(e) AS count
    """, doc_id=doc_id)

    entities_by_type = {rec["entity_type"]: rec["count"] for rec in result}

    # Verify at least some entities extracted
    assert sum(entities_by_type.values()) > 0
    assert "person" in entities_by_type or "skill" in entities_by_type
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-17 | 1.0 | Story created from Epic 3 | Sarah (PO Agent) |

---

## Dev Agent Record

### Agent Model Used
<!-- Populated during implementation -->

### Debug Log References
<!-- Populated during implementation -->

### Completion Notes
<!-- Populated during implementation -->

### File List
<!-- Populated during implementation -->

---

## QA Results
<!-- Results from QA Agent review -->
